{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional, Tuple, Sequence\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Sampler\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA & SAMPLER\n",
    "class MNISTDataset(datasets.MNIST):\n",
    "\n",
    "    N_CLASSES = 10\n",
    "\n",
    "    def __init__(self, root: str, train: bool):\n",
    "        transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,)),\n",
    "            ]\n",
    "        )\n",
    "        super().__init__(root=root, train=train, download=True, transform=transform)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.data[index], self.targets[index]\n",
    "        x = self.transform(x)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "class FederatedSampler(Sampler):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: Sequence,\n",
    "        non_iid: int,\n",
    "        n_clients: Optional[int] = 100,\n",
    "        n_shards: Optional[int] = 200,\n",
    "    ):\n",
    "        \"\"\"Sampler for federated learning in both iid and non-iid settings.\n",
    "\n",
    "        Args:\n",
    "            dataset (Sequence): Dataset to sample from.\n",
    "            non_iid (int): 0: IID, 1: Non-IID\n",
    "            n_clients (Optional[int], optional): Number of clients. Defaults to 100.\n",
    "            n_shards (Optional[int], optional): Number of shards. Defaults to 200.\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.non_iid = non_iid\n",
    "        self.n_clients = n_clients\n",
    "        self.n_shards = n_shards\n",
    "\n",
    "        if self.non_iid:\n",
    "            self.dict_users = self._sample_non_iid()\n",
    "        else:\n",
    "            self.dict_users = self._sample_iid()\n",
    "\n",
    "    def _sample_iid(self) -> Dict[int, List[int]]:\n",
    "        num_items = int(len(self.dataset) / self.n_clients)\n",
    "        dict_users, all_idxs = {}, [i for i in range(len(self.dataset))]\n",
    "\n",
    "        for i in range(self.n_clients):\n",
    "            dict_users[i] = set(np.random.choice(all_idxs, num_items, replace=False))\n",
    "            all_idxs = list(set(all_idxs) - dict_users[i])\n",
    "\n",
    "        return dict_users\n",
    "\n",
    "    def _sample_non_iid(self) -> Dict[int, List[int]]:\n",
    "        num_imgs = len(self.dataset) // self.n_shards  # 300\n",
    "\n",
    "        idx_shard = [i for i in range(self.n_shards)]\n",
    "        dict_users = {i: np.array([]) for i in range(self.n_clients)}\n",
    "        idxs = np.arange(self.n_shards * num_imgs)\n",
    "        labels = self.dataset.targets.numpy()\n",
    "\n",
    "        # sort labels\n",
    "        idxs_labels = np.vstack((idxs, labels))\n",
    "        idxs_labels = idxs_labels[:, idxs_labels[1, :].argsort()]\n",
    "        idxs = idxs_labels[0, :]\n",
    "\n",
    "        # divide and assign 2 shards/client\n",
    "        for i in range(self.n_clients):\n",
    "            rand_set = set(np.random.choice(idx_shard, 2, replace=False))\n",
    "            idx_shard = list(set(idx_shard) - rand_set)\n",
    "            for rand in rand_set:\n",
    "                dict_users[i] = np.concatenate(\n",
    "                    (dict_users[i], idxs[rand * num_imgs : (rand + 1) * num_imgs]),\n",
    "                    axis=0,\n",
    "                )\n",
    "\n",
    "        return dict_users\n",
    "\n",
    "    def set_client(self, client_id: int):\n",
    "        self.client_id = client_id\n",
    "\n",
    "    def __iter__(self):\n",
    "        # fetch dataset indexes based on current client\n",
    "        client_idxs = list(self.dict_users[self.client_id])\n",
    "        for item in client_idxs:\n",
    "            yield int(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELS\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, n_classes: int):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, n_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return self.softmax(x)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_channels: int, n_classes: int):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(n_channels, 32, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(-1, 1024)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILS\n",
    "class Logger:\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "\n",
    "    def log(self, logs: Dict[str, Any]) -> None:\n",
    "        print(logs)\n",
    "\n",
    "def average_weights(weights: List[Dict[str, torch.Tensor]]) -> Dict[str, torch.Tensor]:\n",
    "    weights_avg = copy.deepcopy(weights[0])\n",
    "\n",
    "    for key in weights_avg.keys():\n",
    "        for i in range(1, len(weights)):\n",
    "            weights_avg[key] += weights[i][key]\n",
    "        weights_avg[key] = torch.div(weights_avg[key], len(weights))\n",
    "\n",
    "    return weights_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEDAVG\n",
    "class FedAvg:\n",
    "    def __init__(self, args: Dict[str, Any]):\n",
    "        self.args = args\n",
    "        self.device = torch.device(\n",
    "            f\"cuda:{args.device}\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        self.logger = Logger(args)\n",
    "\n",
    "        self.train_loader, self.test_loader = self._get_data(\n",
    "            n_clients=self.args.n_clients,\n",
    "            n_shards=self.args.n_shards,\n",
    "            non_iid=self.args.non_iid,\n",
    "        )\n",
    "\n",
    "        if self.args.model_name == \"mlp\":\n",
    "            self.root_model = MLP(input_size=784, hidden_size=128, n_classes=10).to(\n",
    "                self.device\n",
    "            )\n",
    "            self.target_acc = 0.97\n",
    "        elif self.args.model_name == \"cnn\":\n",
    "            self.root_model = CNN(n_channels=1, n_classes=10).to(self.device)\n",
    "            self.target_acc = 0.99\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid model name, {self.args.model_name}\")\n",
    "\n",
    "        self.reached_target_at = None  # type: int\n",
    "\n",
    "    def _get_data(\n",
    "        self, n_clients: int, n_shards: int, non_iid: int\n",
    "    ) -> Tuple[DataLoader, DataLoader]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_clients (int): number of clients.\n",
    "            n_shards (int): number of shards.\n",
    "            non_iid (int): 0: IID, 1: Non-IID\n",
    "\n",
    "        Returns:\n",
    "            Tuple[DataLoader, DataLoader]: train_loader, test_loader\n",
    "        \"\"\"\n",
    "        train_set = MNISTDataset(root='./data', train=True)\n",
    "        test_set = MNISTDataset(root='./data', train=False)\n",
    "\n",
    "        sampler = FederatedSampler(\n",
    "            train_set, non_iid=non_iid, n_clients=n_clients, n_shards=n_shards\n",
    "        )\n",
    "\n",
    "        train_loader = DataLoader(train_set, batch_size=128, sampler=sampler)\n",
    "        test_loader = DataLoader(test_set, batch_size=128)\n",
    "\n",
    "        return train_loader, test_loader\n",
    "\n",
    "    def _train_client(\n",
    "        self, root_model: nn.Module, train_loader: DataLoader, client_idx: int\n",
    "    ) -> Tuple[nn.Module, float]:\n",
    "        \"\"\"Train a client model.\n",
    "\n",
    "        Args:\n",
    "            root_model (nn.Module): server model.\n",
    "            train_loader (DataLoader): client data loader.\n",
    "            client_idx (int): client index.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[nn.Module, float]: client model, average client loss.\n",
    "        \"\"\"\n",
    "        model = copy.deepcopy(root_model)\n",
    "        model.train()\n",
    "        optimizer = torch.optim.SGD(\n",
    "            model.parameters(), lr=self.args.lr, momentum=self.args.momentum\n",
    "        )\n",
    "\n",
    "        for epoch in range(self.args.n_client_epochs):\n",
    "            epoch_loss = 0.0\n",
    "            epoch_correct = 0\n",
    "            epoch_samples = 0\n",
    "\n",
    "            for idx, (data, target) in enumerate(train_loader):\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                logits = model(data)\n",
    "                loss = F.nll_loss(logits, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                epoch_correct += (logits.argmax(dim=1) == target).sum().item()\n",
    "                epoch_samples += data.size(0)\n",
    "\n",
    "            # Calculate average accuracy and loss\n",
    "            epoch_loss /= idx\n",
    "            epoch_acc = epoch_correct / epoch_samples\n",
    "\n",
    "            print(\n",
    "                f\"Client #{client_idx} | Epoch: {epoch}/{self.args.n_client_epochs} | Loss: {epoch_loss} | Acc: {epoch_acc}\",\n",
    "                end=\"\\r\",\n",
    "            )\n",
    "\n",
    "        return model, epoch_loss / self.args.n_client_epochs\n",
    "\n",
    "    def train(self) -> None:\n",
    "        \"\"\"Train a server model.\"\"\"\n",
    "        train_losses = []\n",
    "\n",
    "        for epoch in range(self.args.n_epochs):\n",
    "            clients_models = []\n",
    "            clients_losses = []\n",
    "\n",
    "            # Randomly select clients\n",
    "            m = max(int(self.args.frac * self.args.n_clients), 1)\n",
    "            idx_clients = np.random.choice(range(self.args.n_clients), m, replace=False)\n",
    "\n",
    "            # Train clients\n",
    "            self.root_model.train()\n",
    "\n",
    "            for client_idx in idx_clients:\n",
    "                # Set client in the sampler\n",
    "                self.train_loader.sampler.set_client(client_idx)\n",
    "\n",
    "                # Train client\n",
    "                client_model, client_loss = self._train_client(\n",
    "                    root_model=self.root_model,\n",
    "                    train_loader=self.train_loader,\n",
    "                    client_idx=client_idx,\n",
    "                )\n",
    "                clients_models.append(client_model.state_dict())\n",
    "                clients_losses.append(client_loss)\n",
    "\n",
    "            # Update server model based on clients models\n",
    "            updated_weights = average_weights(clients_models)\n",
    "            self.root_model.load_state_dict(updated_weights)\n",
    "\n",
    "            # Update average loss of this round\n",
    "            avg_loss = sum(clients_losses) / len(clients_losses)\n",
    "            train_losses.append(avg_loss)\n",
    "\n",
    "            if (epoch + 1) % self.args.log_every == 0:\n",
    "                # Test server model\n",
    "                total_loss, total_acc = self.test()\n",
    "                avg_train_loss = sum(train_losses) / len(train_losses)\n",
    "\n",
    "                # Log results\n",
    "                logs = {\n",
    "                    \"train/loss\": avg_train_loss,\n",
    "                    \"test/loss\": total_loss,\n",
    "                    \"test/acc\": total_acc,\n",
    "                    \"round\": epoch,\n",
    "                }\n",
    "                if total_acc >= self.target_acc and self.reached_target_at is None:\n",
    "                    self.reached_target_at = epoch\n",
    "                    logs[\"reached_target_at\"] = self.reached_target_at\n",
    "                    print(\n",
    "                        f\"\\n -----> Target accuracy {self.target_acc} reached at round {epoch}! <----- \\n\"\n",
    "                    )\n",
    "\n",
    "                self.logger.log(logs)\n",
    "\n",
    "                # Print results to CLI\n",
    "                print(f\"\\n\\nResults after {epoch + 1} rounds of training:\")\n",
    "                print(f\"---> Avg Training Loss: {avg_train_loss}\")\n",
    "                print(\n",
    "                    f\"---> Avg Test Loss: {total_loss} | Avg Test Accuracy: {total_acc}\\n\"\n",
    "                )\n",
    "\n",
    "                # Early stopping\n",
    "                if self.args.early_stopping and self.reached_target_at is not None:\n",
    "                    print(f\"\\nEarly stopping at round #{epoch}...\")\n",
    "                    break\n",
    "\n",
    "    def test(self) -> Tuple[float, float]:\n",
    "        \"\"\"Test the server model.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[float, float]: average loss, average accuracy.\n",
    "        \"\"\"\n",
    "        self.root_model.eval()\n",
    "\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0.0\n",
    "        total_samples = 0\n",
    "\n",
    "        for idx, (data, target) in enumerate(self.test_loader):\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "\n",
    "            logits = self.root_model(data)\n",
    "            loss = F.nll_loss(logits, target)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_correct += (logits.argmax(dim=1) == target).sum().item()\n",
    "            total_samples += data.size(0)\n",
    "\n",
    "        # calculate average accuracy and loss\n",
    "        total_loss /= idx\n",
    "        total_acc = total_correct / total_samples\n",
    "\n",
    "        return total_loss, total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train/loss': 0.0006421083043869658, 'test/loss': 2.1293575091239734, 'test/acc': 0.2726, 'round': 0}\n",
      "\n",
      "\n",
      "Results after 1 rounds of training:\n",
      "---> Avg Training Loss: 0.0006421083043869658\n",
      "---> Avg Test Loss: 2.1293575091239734 | Avg Test Accuracy: 0.2726\n",
      "\n",
      "{'train/loss': 0.0004090876436589497, 'test/loss': 1.8342124300125318, 'test/acc': 0.5228, 'round': 1}\n",
      "\n",
      "\n",
      "Results after 2 rounds of training:\n",
      "---> Avg Training Loss: 0.0004090876436589497\n",
      "---> Avg Test Loss: 1.8342124300125318 | Avg Test Accuracy: 0.5228\n",
      "\n",
      "{'train/loss': 0.00031939172990191525, 'test/loss': 1.1643322041401496, 'test/acc': 0.6168, 'round': 2}\n",
      "\n",
      "\n",
      "Results after 3 rounds of training:\n",
      "---> Avg Training Loss: 0.00031939172990191525\n",
      "---> Avg Test Loss: 1.1643322041401496 | Avg Test Accuracy: 0.6168\n",
      "\n",
      "{'train/loss': 0.0002773267267350416, 'test/loss': 1.1384692451892755, 'test/acc': 0.5965, 'round': 3}\n",
      "\n",
      "\n",
      "Results after 4 rounds of training:\n",
      "---> Avg Training Loss: 0.0002773267267350416\n",
      "---> Avg Test Loss: 1.1384692451892755 | Avg Test Accuracy: 0.5965\n",
      "\n",
      "{'train/loss': 0.00023409190954246434, 'test/loss': 2.286422769228617, 'test/acc': 0.4436, 'round': 4}\n",
      "\n",
      "\n",
      "Results after 5 rounds of training:\n",
      "---> Avg Training Loss: 0.00023409190954246434\n",
      "---> Avg Test Loss: 2.286422769228617 | Avg Test Accuracy: 0.4436\n",
      "\n",
      "{'train/loss': 0.0002230592065964965, 'test/loss': 1.2027458273447478, 'test/acc': 0.6326, 'round': 5}\n",
      "\n",
      "\n",
      "Results after 6 rounds of training:\n",
      "---> Avg Training Loss: 0.0002230592065964965\n",
      "---> Avg Test Loss: 1.2027458273447478 | Avg Test Accuracy: 0.6326\n",
      "\n",
      "{'train/loss': 0.00020604815324850562, 'test/loss': 1.3160397127652779, 'test/acc': 0.6491, 'round': 6}\n",
      "\n",
      "\n",
      "Results after 7 rounds of training:\n",
      "---> Avg Training Loss: 0.00020604815324850562\n",
      "---> Avg Test Loss: 1.3160397127652779 | Avg Test Accuracy: 0.6491\n",
      "\n",
      "{'train/loss': 0.00020604648788429607, 'test/loss': 1.0071052763706598, 'test/acc': 0.7251, 'round': 7}\n",
      "\n",
      "\n",
      "Results after 8 rounds of training:\n",
      "---> Avg Training Loss: 0.00020604648788429607\n",
      "---> Avg Test Loss: 1.0071052763706598 | Avg Test Accuracy: 0.7251\n",
      "\n",
      "{'train/loss': 0.00020523099773628973, 'test/loss': 0.786186831883895, 'test/acc': 0.8245, 'round': 8}\n",
      "\n",
      "\n",
      "Results after 9 rounds of training:\n",
      "---> Avg Training Loss: 0.00020523099773628973\n",
      "---> Avg Test Loss: 0.786186831883895 | Avg Test Accuracy: 0.8245\n",
      "\n",
      "{'train/loss': 0.00019158694024186987, 'test/loss': 0.5254251001737057, 'test/acc': 0.7988, 'round': 9}\n",
      "\n",
      "\n",
      "Results after 10 rounds of training:\n",
      "---> Avg Training Loss: 0.00019158694024186987\n",
      "---> Avg Test Loss: 0.5254251001737057 | Avg Test Accuracy: 0.7988\n",
      "\n",
      "{'train/loss': 0.0001807709659613936, 'test/loss': 0.36524282758816695, 'test/acc': 0.8652, 'round': 10}\n",
      "\n",
      "\n",
      "Results after 11 rounds of training:\n",
      "---> Avg Training Loss: 0.0001807709659613936\n",
      "---> Avg Test Loss: 0.36524282758816695 | Avg Test Accuracy: 0.8652\n",
      "\n",
      "{'train/loss': 0.0001691396761473523, 'test/loss': 0.5262199670840533, 'test/acc': 0.8331, 'round': 11}\n",
      "\n",
      "\n",
      "Results after 12 rounds of training:\n",
      "---> Avg Training Loss: 0.0001691396761473523\n",
      "---> Avg Test Loss: 0.5262199670840533 | Avg Test Accuracy: 0.8331\n",
      "\n",
      "{'train/loss': 0.00016295471064284566, 'test/loss': 0.38994438296709305, 'test/acc': 0.8847, 'round': 12}\n",
      "\n",
      "\n",
      "Results after 13 rounds of training:\n",
      "---> Avg Training Loss: 0.00016295471064284566\n",
      "---> Avg Test Loss: 0.38994438296709305 | Avg Test Accuracy: 0.8847\n",
      "\n",
      "Client #18 | Epoch: 16/20 | Loss: 0.002421233701170422 | Acc: 1.0083333333333333\r"
     ]
    }
   ],
   "source": [
    "class Arguments:\n",
    "    def __init__(self):\n",
    "        # 하이퍼파라미터\n",
    "        self.n_client_epochs = 20          # 클라이언트 당 에포크 수\n",
    "        self.non_iid = 1                   # 0: IID, 1: Non-IID\n",
    "        self.lr = 0.01                     # 학습률 (옵션: 0.01, 0.001)\n",
    "\n",
    "        # 고정 설정\n",
    "        self.model_name = \"cnn\"            # 모델 아키텍처 (\"cnn\" 또는 \"mlp\")\n",
    "        self.n_clients = 100               # 클라이언트 수\n",
    "        self.n_shards = 200                # 데이터 샤드 수\n",
    "        self.frac = 0.1                    # 각 라운드마다 참여하는 클라이언트의 비율\n",
    "        self.n_epochs = 1000               # 총 학습 에포크 수\n",
    "\n",
    "        # 디바이스 및 로깅\n",
    "        self.device = 0                    # 디바이스 ID (예: GPU 인덱스)\n",
    "        self.log_every = 1                 # 로깅 빈도 (에포크 단위)\n",
    "        self.early_stopping = True         # 조기 종료 활성화 여부\n",
    "\n",
    "        # 필수 추가 설정\n",
    "        self.momentum = 0.9                # 옵티마이저의 모멘텀 값\n",
    "\n",
    "args = Arguments()\n",
    "fed_avg = FedAvg(args)\n",
    "fed_avg.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
